# -*- coding: utf-8 -*-
"""Copia de solution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mw3l8ZRDR5HkM-V1zBeHCvwZ0rZaMnEK
"""

!wget --no-cache -O init.py -q https://raw.githubusercontent.com/UDEA-Esp-Analitica-y-Ciencia-de-Datos/EACD-01-FUNDAMENTOS/master/init.py
import init; init.init(force_download=False);

"""# Precios de Casas

El objetivo de este taller es realizar un análisis exploratorio de un dataset. El dataset no llega limpio, el proceso de limpieza se encuentra implementado. Después de este proceso de limpieza se debe llevar a cabo el análisis exploratorio.
"""

from collections import Counter, defaultdict

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""## Entendiendo y limpiando el dataset

La descripcion de cada variable puede verse ejecutando la siguiente celda
"""

!cat local/data/houseprices_description.txt

"""Ahora carguemos los datos y hagamos una breve exploración"""

df = pd.read_csv("local/data/houseprices.csv")
df.head()

df.info()

"""Podemos ver que hay una gran cantidad de valores nulos en algunas de las variables. Alguien, algo despistado, podría sugerir simplemente eliminar esas variables; sin embargo, la descripción de las variables que observamos anteriormente, nos permite entender la razón de ser de estos valores nulos y tratarlos de una manera inteligente. Por ejemplo, consideremos la variable `PoolQC` la cual nos muestra únicamente 7 valores no nulos de los 1460 registros que tenemos en total. Su descripción dice:

```
PoolQC: Pool quality
		
       Ex	Excellent
       Gd	Good
       TA	Average/Typical
       Fa	Fair
       NA	No Pool

```

Esta variable hace referencia a la calidad de la piscina en la casa y vemos que `NA` significa que no tiene piscina, lo cual posiblemente tiene mucho impacto en el precio de una casa (pregúntese, ¿estaría dispuesto a pagar más por una casa que tenga piscina?). Además, vemos que existe la variable `PoolArea`, la cual almacena el area de la piscina en $ft^2$, la cual no tiene valores nulos. Dado esto, los valores nulos de la variable `PoolQC` deben corresponder a casos en los que la variable `PoolArea` es cero; validemos esto.
"""

num_total_nulls = df["PoolQC"].isna().sum()
num_nulls_when_poolarea_is_zero = df[df["PoolArea"] == 0]["PoolQC"].isna().sum()
assert num_nulls_when_poolarea_is_zero == num_total_nulls

num_nulls_when_poolarea_is_not_zero = df[df["PoolArea"] != 0]["PoolQC"].isna().sum()
assert num_nulls_when_poolarea_is_not_zero == 0

"""Concluimos que se cumple que todos los valores nulos de la variable `PoolQC` corresponden a casos en los que no hay piscina; por lo tanto, vamos a reemplzar los valores nulos por otro valor que podamos usar en nuestros modelos."""

df["PoolQC"] = df["PoolQC"].fillna("NP")

"""Esta misma lógica debemos usarla a la hora de tratar el resto de las variables con valores nulos de este dataset. Escribiremos algún razonamiento addiconal únicamente cuando haga falta"""

num_total_nulls = df["MiscFeature"].isna().sum()
num_nulls_when_miscval_is_zero = df[df["MiscVal"] == 0]["MiscFeature"].isna().sum()
num_nulls_when_miscval_is_not_zero = df[df["MiscVal"] != 0]["MiscFeature"].isna().sum()
assert num_nulls_when_miscval_is_zero == num_total_nulls
assert num_nulls_when_miscval_is_not_zero == 0
df["MiscFeature"] = df["MiscFeature"].fillna("No MF")

num_total_nulls = df["FireplaceQu"].isna().sum()
num_nulls_when_fireplaces_is_zero = df[df["Fireplaces"] == 0]["FireplaceQu"].isna().sum()
num_nulls_when_fireplaces_is_not_zero = df[df["Fireplaces"] != 0]["FireplaceQu"].isna().sum()
assert num_nulls_when_fireplaces_is_zero == num_total_nulls
assert num_nulls_when_fireplaces_is_not_zero == 0
df["FireplaceQu"] = df["FireplaceQu"].fillna("No FP")

num_area_zeros = (df["GarageArea"] == 0).sum()
num_cars_zeros = (df["GarageCars"] == 0).sum()
num_both_zeros = ((df["GarageArea"] == 0) & (df["GarageCars"] == 0.0)).sum()
assert num_both_zeros == num_area_zeros == num_cars_zeros
for colname in ["GarageType", "GarageFinish", "GarageQual", "GarageCond"]:
    num_total_nulls = df[colname].isna().sum()
    num_nulls_when_area_and_cars_capacity_is_zero = df[(df["GarageArea"] == 0.0) & (df["GarageCars"] == 0.0)][colname].isna().sum()
    num_nulls_when_area_and_cars_capacity_is_not_zero = df[(df["GarageArea"] != 0.0) & (df["GarageCars"] != 0.0)][colname].isna().sum()
    assert num_total_nulls == num_nulls_when_area_and_cars_capacity_is_zero
    assert num_nulls_when_area_and_cars_capacity_is_not_zero == 0
    df[colname] = df[colname].fillna("No Ga")

"""Para la variable `GarageYrBlt` debemos ser más cuidadosos, ya que son números y no strings. Esta variable nos dice el año en que fue construido el garaje y, según lo visto con otras variables relacionadas al garage, los valores nulos corresponden a casos en los que no hay garage. En este caso, vamos a imputar esa variable con un año posterior a la fecha de venta. Esta aproximación podría no funcionar muy bien con modelos lineales, o cuando escalamos los datos, pero no se me ocurre otra!"""

num_total_nulls = df["GarageYrBlt"].isna().sum()
num_nulls_when_area_and_cars_is_zero = df[(df["GarageArea"] == 0.0) & (df["GarageCars"] == 0.0)]["GarageYrBlt"].isna().sum()
num_nulls_when_area_and_cars_is_not_zero = df[(df["GarageArea"] != 0.0) & (df["GarageCars"] != 0.0)]["GarageYrBlt"].isna().sum()
assert num_nulls_when_area_and_cars_is_zero == num_total_nulls
assert num_nulls_when_area_and_cars_is_not_zero == 0
df["GarageYrBlt"].where(~df["GarageYrBlt"].isna(), other=df["YrSold"] + 1, inplace=True)

"""`LotFrontage: Linear feet of street connected to property)`

Valores nulos en esta variable podrían ser ocasionados porque sencillamente no hay conexión de la calle a la propiedad, es decir, que esa longitud medida por esta variable es igual a 0. Podemos asumir que este es el caso únicamente si no hay otro 0 en los valores que ha tomado esta variable, de otra manera ¿por qué algunos tendrían 0 y otros nulos?
"""

assert (df["LotFrontage"] == 0).sum() == 0
df["LotFrontage"].fillna(0, inplace=True)

df["Alley"].fillna("NA", inplace=True)
df["Fence"].fillna("NF", inplace=True)

"""```
MasVnrType: Masonry veneer type

       BrkCmn	Brick Common
       BrkFace	Brick Face
       CBlock	Cinder Block
       None	None
       Stone	Stone
	
MasVnrArea: Masonry veneer area in square feet
```

Una posibilidad es que los valores nulos de `MasVnrType` y `MasVnrArea` correspondan a casos en los que no hay "Masonry veneer" (chapa de albañilería). Esto sería en los casos en que la variable `MasVnrArea` sea 0, esto lo validaremos de la misma manera en que validamos con la variable `LotFrontage`.
"""

assert (df["MasVnrArea"] == 0).sum() == df["MasVnrType"].isnull().sum()

"""Acá la situación es diferente, el error anterior nos dice que los casos para los cuales no tenemos área son distintos de los que el tipo es nulo, entonces nos toca inspeccionar más en detalle. Sabemos que hay 8 valores nulos en cada una de las dos variables, miremos si corresponden a los mismos registros:"""

np.logical_and(df["MasVnrType"].isnull().values, df["MasVnrArea"].isnull().values).sum()

"""En efecto, dado que hay 8 registros para los cuales las dos variables tienen valores nulos, podemos decir que son nulos en ambas partes. A falta de información, vamos a decidir eliminar esos registros por completo, no debe ser muy grave, pues apenas son 8 filas en todo el dataset."""

df = df.dropna(subset=["MasVnrType", "MasVnrArea"])

"""Ahora miremos los valores de cada una"""

df["MasVnrType"].value_counts()

df["MasVnrArea"].value_counts()

"""Acá podemos observar lo siguiente:
- Hay 864 registros con `MasVnrType="None"`
- Hay 861 registros con `MasVnrArea=0`

Eso quiere decir que hay algunos registros que deberían tener un área de 0 y no es así. Vamos a mirar en detalle cuáles son:
"""

df[(df["MasVnrType"] == "None") & (df["MasVnrArea"] != 0.0)]

"""**Francamente** yo no soy un experto en casas, por lo que no tengo forma de deducir a qué se debe esa incoherencia en los datos. Por lo anterior, simplemente voy a eliminar esas filas, ya que tengo dudas de la veracidad de esos datos."""

df = df[~((df["MasVnrType"] == "None") & (df["MasVnrArea"] != 0.0))]

"""La variable `Electrical` tampoco nos ofrece una forma de recuperar esos valores nulos, por lo que también vamos a eliminar ese registro. Nótese que otra opción podría ser reemplazarlo con el valor más común en la misma variable, dado que esta es categórica. """

df.dropna(subset=["Electrical"], inplace=True)

df.info()

"""Ahora miremos las variables relacionadas con el basement:

```

BsmtQual: Evaluates the height of the basement

       Ex	Excellent (100+ inches)	
       Gd	Good (90-99 inches)
       TA	Typical (80-89 inches)
       Fa	Fair (70-79 inches)
       Po	Poor (<70 inches
       NA	No Basement
		
BsmtCond: Evaluates the general condition of the basement

       Ex	Excellent
       Gd	Good
       TA	Typical - slight dampness allowed
       Fa	Fair - dampness or some cracking or settling
       Po	Poor - Severe cracking, settling, or wetness
       NA	No Basement
	
BsmtExposure: Refers to walkout or garden level walls

       Gd	Good Exposure
       Av	Average Exposure (split levels or foyers typically score average or above)	
       Mn	Mimimum Exposure
       No	No Exposure
       NA	No Basement
	
BsmtFinType1: Rating of basement finished area

       GLQ	Good Living Quarters
       ALQ	Average Living Quarters
       BLQ	Below Average Living Quarters	
       Rec	Average Rec Room
       LwQ	Low Quality
       Unf	Unfinshed
       NA	No Basement
		
BsmtFinSF1: Type 1 finished square feet

BsmtFinType2: Rating of basement finished area (if multiple types)

       GLQ	Good Living Quarters
       ALQ	Average Living Quarters
       BLQ	Below Average Living Quarters	
       Rec	Average Rec Room
       LwQ	Low Quality
       Unf	Unfinshed
       NA	No Basement

BsmtFinSF2: Type 2 finished square feet

BsmtUnfSF: Unfinished square feet of basement area

TotalBsmtSF: Total square feet of basement area

```

Dado que los valores nulos en varias de estas variables corresponden a `No Basement`, ahora miremos si los registros nulos en algunas corresponden a los registros nulos en todas. Primero, dado que ya hemos eliminado varios registros, vamos a ver cuántos valores nulos hay en esas variables.
"""

colnames = ["BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1",
    "BsmtFinSF1", "BsmtFinType2", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF"]
for c in colnames:
    print(f"{c} has {df[c].isnull().sum()} null values")

df["TotalBsmtSF"].value_counts()

"""Acá vemos que algunas tienen más variables nulas que otras, lo cual es confuso porque en cualquier caso los valores nulos deberían significar que no hay basement. En este caso vamos a reemplazar los valores en los que los valores nulos sean en todas las variables no numéricas pero los que sobren los eliminaremos."""

colnames = ["BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2"]
cond = ~(df["BsmtQual"].isna() & df["BsmtCond"].isna() & df["BsmtExposure"].isna() & df["BsmtFinType1"].isna() & df["BsmtFinType2"].isna())
for c in colnames:
    df[c].where(cond, other="NB", inplace=True)

df.dropna(inplace=True)
print(f"Number of null values {df.isna().sum().sum()} in a dataframe of shape {df.shape}")

"""## Análisis exploratorio de datos

En esta sección se dejarán preguntas que deben ser respondidas utilizando los datos.

**¿Qué tan viejas son las casas?**
"""

df["HouseAge"] = df["YrSold"] - df["YearBuilt"]
df["HouseAge"].hist(bins=20)

df2 = pd.DataFrame(df[["YearBuilt","YrSold"]])
df2["HouseAge"] = df2["YrSold"] - df2["YearBuilt"]
df2

mean_house_age= np.mean(df["HouseAge"])
min_house_age = np.min(df["HouseAge"])
max_house_age = np.max(df["HouseAge"])
print(f' las casas están entre los {min_house_age} años y {max_house_age} años, con un promedio de {mean_house_age} años')

"""**¿Cómo se relaciona el precio con la edad de la casa?**"""

df3 = pd.DataFrame(df["SalePrice"])
df3["HouseAge"] = df2["YrSold"] - df2["YearBuilt"]
df3

df3.plot('HouseAge','SalePrice', kind = 'scatter')

x = df3.HouseAge
y = df3.SalePrice

fig, ax = plt.subplots(figsize=(4, 4), dpi=100) 

ax.plot(x, y,
        linestyle='None', marker='.', color='tomato',  # estilo de línea
        zorder=2)  # orden para colocar sobre rejilla

z = np.polyfit(x, y, 1)  # ajuste polinómico de grado 1
p = np.poly1d(z)
plt.plot(x, p(x), linewidth=2, alpha=0.8, color='royalblue')

"""R/ = Graficamente se puede observar que las casas más nuevas podrían tener un valor más alto de venta, sin ambargo no hay una relación muy fuerte entre estas dos variabales.

**¿Cuál es el barrio más pobre?**
"""

df4 = pd.DataFrame(df[["Neighborhood","SalePrice"]])
df5 = df4.groupby(by = "Neighborhood").mean().sort_values(by = "SalePrice")
df5

"""R/ A trvés de los datos se puede inferir que las casas con menores condiciones y menos lujos tienen un precio menor, por lo cuál una barrio donde el promedio de los precios es más bajo tiene pobres condiciones, ejemplo MeadowV y IDOTRR

**¿Cuál es el barrio más cercano a vías férreas?**
"""

df6 = pd.DataFrame(df[["Neighborhood","Condition1","Condition2"]])
proximity_railroad = df6[(df6.Condition1.isin(["RRNn","RRAn","RRNe","RRAe"]) | df6.Condition2.isin(["RRNn","RRAn","RRNe","RRAe"]))]
proximity_railroad['Contar'] = 1
proximity_railroad

proximity_railroad.groupby( by = "Neighborhood").sum('Contar').sort_values(by = 'Contar', ascending = False)

"""R/ = Los barrios más cercanos a vías ferreas son BrkSide y Giilbert

**¿Cuál es la cobertura más común en las casas que se encuentran el el top 10% en precio?**
"""

cobertura = pd.DataFrame(df[["Id","SalePrice","Exterior1st","Exterior2nd"]])
cobertura.sort_values(by = "SalePrice", ascending = False)

arry = df[["SalePrice"]]
percentile = np.percentile(arry, 90)

diez_por_ciento = cobertura[cobertura['SalePrice'] >= percentile]
diez_por_ciento

cobertura1 = pd.DataFrame(diez_por_ciento.groupby(by = "Exterior1st").size())
cobertura2 = pd.DataFrame(diez_por_ciento.groupby(by = "Exterior2nd").size())

cobertura1 , cobertura2

"""R/ la cobertura más común en las casas que se encuentran el el top 10% en precio es la VinylSd

**¿En qué barrio hay mayor desigualdad?**
"""

desigualdad = pd.DataFrame(df[["Neighborhood","SalePrice"]])
#desigualdad.groupby( by = "Neighborhood")
bigotes = desigualdad.boxplot(column="SalePrice", by="Neighborhood", figsize = (20,8))
#desigualdad.set_xticklabels(labels, rotation=90)
#bigotes.invert_yaxis()
bigotes

desigualdad.groupby( by = "Neighborhood").std()

"""R/ El barrio con más desigualdad es el NoRidge pues presenta una mayor desviación en los precios de las casas

**¿En qué año hubo más movimiento del mercado inmobiliario?**
"""

df_mercado = pd.DataFrame(df.groupby( by = "YrSold").size())
df_mercado

import matplotlib.ticker as ticker
import math
grafica = df_mercado.plot()
plt.xticks(np.arange(2006, 2011))
plt.show()

"""R/ El año en que hubo más movimiento inmobiliario fue en el 2009 con 334 casa vendidas

**¿Cuáles son los 2 barrios con mayor industria cerca?**
"""

zona = pd.DataFrame(df[["Neighborhood","MSZoning"]])
zona_industrial = zona[(zona.MSZoning.isin(["I"]))]
zona_industrial

"""R/ No hay barrios con industria cerca

**¿Cuáles son los 2 barrios con mayor comercio cerca?**
"""

comercio = pd.DataFrame(df[["Neighborhood","MSZoning"]])
zona_comercial = zona[(zona.MSZoning.isin(["C (all)"]))]
zona_comercial

"""R/ Los dos barrios con mayor comercio cerca son IDOTRR Y OldTown"""